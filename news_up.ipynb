{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b12e9387-9742-4dcb-8872-0986a871e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7376a33a-4ec0-4495-aab1-0d7599654ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "210ebe64-0cc0-402e-bdaa-ab648ea9ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86aa4cd8-0a50-41d9-b279-7a7fb1dc1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import SnowballStemmer\n",
    "stem = SnowballStemmer(\"english\")\n",
    "lem=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43a16114-6b33-4f63-a093-3bd2191ff42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tfidf Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68862b72-e032-4949-a502-f19cbef3df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"True or Fake Text Classification\")\n",
    "\n",
    "st.write(\"Enter a text to determine if it is True or Fake.\")\n",
    "\n",
    "# Get user input\n",
    "user_input = st.text_area(\"Input Text\")\n",
    "def clean_words(text):\n",
    "    # Define a regex pattern for URLs\n",
    "    url_pattern = re.compile(r'http[s]?://\\S+')\n",
    "    \n",
    "    # Remove URLs from the text\n",
    "    text = re.sub(url_pattern, '', text)\n",
    "    doc= nlp(text)\n",
    "    clean_text=[x.lemma_ for x in doc if not x.is_stop and not x.is_punct and not x.like_num and not x.is_bracket and not x.pos_ in ['SYM']]\n",
    "    clean_text=[stem.stem(x) for x in clean_text]\n",
    "    return ' '.join(clean_text)\n",
    "\n",
    "try :\n",
    "    mod=pickle.load(open('model.pkl','rb'))\n",
    "    vect=pickle.load(open('vector.pkl','rb'))\n",
    "except Exception as e :\n",
    "    st.error(str(e))\n",
    "\n",
    "if len(user_input) != 0:\n",
    "    df = pd.DataFrame({'text':user_input}, index=[0]) \n",
    "    df['text'] = df['text'].apply(clean_words)\n",
    "    new_data = vect.transform(df['text'])   \n",
    "\n",
    "if st.button('Predict') :\n",
    "    prediction = mod.predict(new_data) \n",
    "    if prediction[0] == 1 :\n",
    "        st.error('News is Real ')\n",
    "    else :\n",
    "        st.success('News is Fake ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c3b237-76d7-44e0-983a-9d69ae09708a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
